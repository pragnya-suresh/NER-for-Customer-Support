{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "from textacy import lexicon_methods\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import csv\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords \n",
    "import math\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from numpy import array \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "ps = PorterStemmer()\n",
    "from spacy.parts_of_speech import ADJ, ADV, NOUN, VERB\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Flatten\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import MaxPooling1D\n",
    "from os import path\n",
    "from __future__ import unicode_literals, print_function\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from ahocorasick import Automaton\n",
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''train a model  to categorize the reviews based on positive and negative sentiments. So output of svm will be 1  and 1\n",
    "0-negative\n",
    "Take the negative sentiment reviews and apply ner\n",
    "These are the reviews that have issues\n",
    "Once the entities have been recognised, the review can be routed to the corresponding dept\n",
    "We can show it in a table -review, corresponding department\n",
    "And another table that can have review, corresponding response.\n",
    "Ex:  Review: few weeks ago I ordered some cotton tops. They sent me some cheap nylon tops instead. \n",
    "     Response :What was the brand of the top?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Categories:\n",
    "#1. Clothing and Accessories\n",
    "#2. Cell_Phones_Accessories.txt\n",
    "#3. Home_Kitchen.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/pragnyasuresh/Downloads/Clothing_Accessories.txt', 'r') as f:\n",
    "    with open('/Users/pragnyasuresh/Desktop/nlp_project/reviews.csv', 'w') as writeFile:\n",
    "        writer = csv.writer(writeFile)\n",
    "        header=[\"department\",\"sentiment\",\"review\"]\n",
    "        writer.writerow(header)\n",
    "        ctr=0\n",
    "        for line in f:\n",
    "            if(line.find(\"review/score:\")!=-1):\n",
    "                    \n",
    "                    rev=[\"Clothing_Accessories\",line[13:]]\n",
    "            \n",
    "            \n",
    "            \n",
    "            if(line.find(\"review/text:\")!=-1 and ctr<4000):\n",
    "                \n",
    "                review=str(line[13:]).lower()\n",
    "                #print(review)\n",
    "                rev.append(review)\n",
    "                \n",
    "                #print(rev)\n",
    "                \n",
    "                writer = csv.writer(writeFile)\n",
    "                writer.writerow(rev)\n",
    "                ctr+=1\n",
    "            \n",
    "            \n",
    "    print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/pragnyasuresh/Downloads/Cell_Phones_Accessories.txt', 'r') as f:\n",
    "    with open('/Users/pragnyasuresh/Desktop/nlp_project/reviews.csv', 'a') as writeFile:\n",
    "\n",
    "       \n",
    "\n",
    "        ctr=0\n",
    "        for line in f:\n",
    "            \n",
    "            if(line.find(\"review/score:\")!=-1):\n",
    "                    \n",
    "                    rev=[\"Cell_Phones_Accessories\",line[13:]]\n",
    "            \n",
    "            \n",
    "            \n",
    "            if(line.find(\"review/text:\")!=-1 and ctr<4000):\n",
    "                \n",
    "            \n",
    "                review=str(line[13:]).lower()\n",
    "                #print(review)\n",
    "                rev.append(review)\n",
    "                \n",
    "                #print(rev)\n",
    "                \n",
    "                writer = csv.writer(writeFile)\n",
    "                writer.writerow(rev)\n",
    "                ctr+=1\n",
    "            \n",
    "            \n",
    "    print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/pragnyasuresh/Downloads/Home_Kitchen.txt', 'r') as f:\n",
    "    with open('/Users/pragnyasuresh/Desktop/nlp_project/reviews.csv', 'a') as writeFile:\n",
    "\n",
    "       \n",
    "        ctr=0\n",
    "        for line in f:\n",
    "            \n",
    "            if(line.find(\"review/score:\")!=-1):\n",
    "                    \n",
    "                    rev=[\"Home_Kitchen\",line[13:]]\n",
    "            \n",
    "            \n",
    "            \n",
    "            if(line.find(\"review/text:\")!=-1 and ctr<4000):\n",
    "                \n",
    "                review=str(line[13:]).lower()\n",
    "                #print(review)\n",
    "                rev.append(review)\n",
    "                \n",
    "                #print(rev)\n",
    "                \n",
    "                writer = csv.writer(writeFile)\n",
    "                writer.writerow(rev)\n",
    "                ctr+=1\n",
    "            \n",
    "            \n",
    "    print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n",
      "5.0    6064\n",
      "4.0    2349\n",
      "1.0    1530\n",
      "3.0    1120\n",
      "2.0     937\n",
      "Name: sentiment, dtype: int64\n",
      "10880\n",
      "1.0    8413\n",
      "0.0    2467\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('/Users/pragnyasuresh/Desktop/nlp_project/reviews.csv', delimiter = ',')\n",
    "print(len(df))\n",
    "print(df['sentiment'].value_counts())\n",
    "#Drop all the reviews with rating 3\n",
    "\n",
    "df = df[df.sentiment != 3]\n",
    "print(len(df))\n",
    "df['sentiment']=df['sentiment'].replace([1, 2], 0)\n",
    "df['sentiment']=df['sentiment'].replace([4, 5], 1)\n",
    "print(df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3773 2467\n",
      "Clothing_Accessories       3650\n",
      "Cell_Phones_Accessories    2021\n",
      "Home_Kitchen                569\n",
      "Name: department, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#balance\n",
    "df1=df.loc[df['sentiment'] == 1]\n",
    "df2=df.loc[df['sentiment'] == 0]\n",
    "\n",
    "df1=df1[:3773]\n",
    "print(len(df1),len(df2))\n",
    "\n",
    "df=df1.append(df2, ignore_index=True)\n",
    "print(df['department'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating sparse vector using TFID vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "sparse_vector = vectorizer.fit_transform(df[\"review\"])\n",
    "n_features=sparse_vector.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using sparse vector representation of each review = 92.90865384615384\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sparse_vector, df[\"sentiment\"], test_size=0.4, random_state=42)\n",
    "l1=list(df[\"department\"])\n",
    "l2=list(df[\"review\"])\n",
    "l=[]\n",
    "for i in range(len(l1)):\n",
    "    l.append([l1[i],l2[i]])\n",
    "#print(len(l))\n",
    "#need to map the reviews and department to the review. To do this, the line below is used. It will split the same way\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(l, df[\"sentiment\"], test_size=0.4, random_state=42)\n",
    "clf = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "clf.fit(X_train, y_train) \n",
    "#Predicting and evaluatng accuracy\n",
    "\n",
    "y_pred_list=clf.predict(X_test)\n",
    "ans=array(y_pred_list)\n",
    "acc = sklearn.metrics.accuracy_score(y_test, y_pred_list)\n",
    "print(\"Accuracy using sparse vector representation of each review =\",acc*100)\n",
    "#Since we needed to manually annotate the corpus for training the ner, we could not use a huge corpus\n",
    "#NN needs huge amount of data to provide good accuracy.\n",
    "#SVM classification gave much better accuracy whereas ANN gave about 72% so we decided to use SVM to classify the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    1538\n",
      "0.0     958\n",
      "Name: sent, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Cell_Phones_Accessories    480\n",
       "Clothing_Accessories       255\n",
       "Home_Kitchen               223\n",
       "Name: department, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we now take all reviews with a negative sentiment\n",
    "y_pred_list=list(y_pred_list)\n",
    "df_pred = pd.DataFrame({'sent':y_pred_list})\n",
    "\n",
    "print (df_pred[\"sent\"].value_counts())\n",
    "X_test2=list(X_test2)\n",
    "negative_reviews=[]\n",
    "j=0\n",
    "with open('/Users/pragnyasuresh/Desktop/nlp_project/negative_reviews.csv', 'w') as writeFile:\n",
    "    header=[\"department\",\"review\"]\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerow(header)\n",
    "    for i in y_pred_list:\n",
    "    \n",
    "        if(i==0.0):\n",
    "            #print(i,j)\n",
    "            negative_reviews=[X_test2[j][0]]\n",
    "            negative_reviews.append(X_test2[j][1])\n",
    "            #print(negative_reviews)\n",
    "            writer = csv.writer(writeFile)\n",
    "            writer.writerow(negative_reviews)\n",
    "        j+=1\n",
    "df_neg = pd.read_csv('/Users/pragnyasuresh/Desktop/nlp_project/negative_reviews.csv') \n",
    "df_neg[\"department\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#perform ner on negative_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using sparse vector representation of each review = 83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "df_neg['department']=df_neg['department'].replace(\"Clothing_Accessories\", 1)\n",
    "df_neg['department']=df_neg['department'].replace(\"Cell_Phones_Accessories\", 2)\n",
    "df_neg['department']=df_neg['department'].replace(\"Home_Kitchen\", 3)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "sparse_vector_neg = vectorizer.fit_transform(df_neg[\"review\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(sparse_vector_neg, df_neg[\"department\"], test_size=0.4, random_state=42)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(df_neg[\"review\"], df_neg[\"department\"], test_size=0.4, random_state=42)\n",
    "\n",
    "clf = svm.SVC(gamma='scale', decision_function_shape='ovo')\n",
    "clf.fit(X_train,y_train) \n",
    "\n",
    "y_pred_list=clf.predict(X_test)\n",
    "ans=array(y_pred_list)\n",
    "acc = sklearn.metrics.accuracy_score(y_test, y_pred_list)\n",
    "print(\"Accuracy using sparse vector representation of each review =\",acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_neg_dept = pd.DataFrame({'dept':y_pred_list,'rev':X_test2})\n",
    "df_neg_dept.to_csv(\"/Users/pragnyasuresh/Desktop/nlp_project/classified_reviews.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, ('Product', 'top')) I recently bought a top from the brand Roadster\n",
      "(46, ('Brand', 'Roadster')) I recently bought a top from the brand Roadster\n",
      "(18, ('Product', 'top')) The size of the top was small\n",
      "(28, ('INFO', 'small')) The size of the top was small\n",
      "(36, ('INFO', 'cotton')) A few weeks ago I ordered some cotton tops. They sent me some cheap nylon tops instead.\n",
      "(40, ('Product', 'top')) A few weeks ago I ordered some cotton tops. They sent me some cheap nylon tops instead.\n",
      "(72, ('INFO', 'nylon')) A few weeks ago I ordered some cotton tops. They sent me some cheap nylon tops instead.\n",
      "(76, ('Product', 'top')) A few weeks ago I ordered some cotton tops. They sent me some cheap nylon tops instead.\n",
      "(21, ('Product', 'top')) I did not like the top that I got\n",
      "(8, ('INFO', 'small')) The small size itself was large\n",
      "(30, ('INFO', 'large')) The small size itself was large\n"
     ]
    }
   ],
   "source": [
    "A=Automaton()\n",
    "A.add_word(\"Roadster\",('Brand','Roadster'))\n",
    "A.add_word(\"top\",('Product','top'))\n",
    "A.add_word(\"nylon\",('INFO','nylon'))\n",
    "A.add_word(\"cotton\",('INFO','cotton'))\n",
    "A.add_word(\"small\",('INFO','small'))\n",
    "A.add_word(\"large\",('INFO','large'))\n",
    " \n",
    "A.make_automaton()\n",
    "e=[\"I recently bought a top from the brand Roadster\",\"The size of the top was small\", \"A few weeks ago I ordered some cotton tops. They sent me some cheap nylon tops instead.\",\"I did not like the top that I got\",\"The small size itself was large\"]\n",
    "for x in e:\n",
    "    for item in A.iter(x):\n",
    "        print(item, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
